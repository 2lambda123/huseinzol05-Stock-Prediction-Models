{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evolution-strategy-bayesian-agent.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "OBmELWHxAOR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install"
      ]
    },
    {
      "metadata": {
        "id": "3hWX8kqN6_kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install bayesian-optimization==0.6 --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZgzBVDZX6_lP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I use `bayesian-optimization==0.6`, my backend pretty much stick with this version, so migrating will break the code."
      ]
    },
    {
      "metadata": {
        "id": "A-4w4W5R__-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "Xgenym7A6_lV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from bayes_opt import BayesianOptimization\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYtPbMi-6_ll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "import types\n",
        "\n",
        "\n",
        "def get_imports():\n",
        "    for name, val in globals().items():\n",
        "        if isinstance(val, types.ModuleType):\n",
        "            name = val.__name__.split('.')[0]\n",
        "        elif isinstance(val, type):\n",
        "            name = val.__module__.split('.')[0]\n",
        "        poorly_named_packages = {'PIL': 'Pillow', 'sklearn': 'scikit-learn'}\n",
        "        if name in poorly_named_packages.keys():\n",
        "            name = poorly_named_packages[name]\n",
        "        yield name\n",
        "\n",
        "\n",
        "imports = list(set(get_imports()))\n",
        "requirements = []\n",
        "for m in pkg_resources.working_set:\n",
        "    if m.project_name in imports and m.project_name != 'pip':\n",
        "        requirements.append((m.project_name, m.version))\n",
        "\n",
        "for r in requirements:\n",
        "    print('{}=={}'.format(*r))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7yYNUCO_6Su",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "9rsN62uj6_mN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TSLA Time Period: **Mar 23, 2018 - Mar 23, 2019**"
      ]
    },
    {
      "metadata": {
        "id": "I3TnTXyr7PQ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!wget https://raw.githubusercontent.com/huseinzol05/Stock-Prediction-Models/master/dataset/TSLA.csv -P dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zI83Cntk6_mR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../dataset/TSLA.csv')\n",
        "df.head()\n",
        "ticker = \"TSLA\"# display ticker name in plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6Xs9mSZ_gXg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Strategy, Model, & Agent"
      ]
    },
    {
      "metadata": {
        "id": "pDyWgvPW6_ml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "close = df.Close.values.tolist()\n",
        "window_size = 30\n",
        "skip = 5\n",
        "l = len(close) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LVBzfGI6_l-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_state(data, t, n):\n",
        "    d = t - n + 1\n",
        "    block = data[d : t + 1] if d >= 0 else -d * [data[0]] + data[0 : t + 1]\n",
        "    res = []\n",
        "    for i in range(n - 1):\n",
        "        res.append(block[i + 1] - block[i])\n",
        "    return np.array([res])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLCLaj336_nQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Deep_Evolution_Strategy:\n",
        "\n",
        "    inputs = None\n",
        "\n",
        "    def __init__(\n",
        "        self, weights, reward_function, population_size, sigma, learning_rate\n",
        "    ):\n",
        "        self.weights = weights\n",
        "        self.reward_function = reward_function\n",
        "        self.population_size = population_size\n",
        "        self.sigma = sigma\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def _get_weight_from_population(self, weights, population):\n",
        "        weights_population = []\n",
        "        for index, i in enumerate(population):\n",
        "            jittered = self.sigma * i\n",
        "            weights_population.append(weights[index] + jittered)\n",
        "        return weights_population\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights\n",
        "\n",
        "    def train(self, epoch = 100, print_every = 1):\n",
        "        lasttime = time.time()\n",
        "        for i in range(epoch):\n",
        "            population = []\n",
        "            rewards = np.zeros(self.population_size)\n",
        "            for k in range(self.population_size):\n",
        "                x = []\n",
        "                for w in self.weights:\n",
        "                    x.append(np.random.randn(*w.shape))\n",
        "                population.append(x)\n",
        "            for k in range(self.population_size):\n",
        "                weights_population = self._get_weight_from_population(\n",
        "                    self.weights, population[k]\n",
        "                )\n",
        "                rewards[k] = self.reward_function(weights_population)\n",
        "            rewards = (rewards - np.mean(rewards)) / np.std(rewards)\n",
        "            for index, w in enumerate(self.weights):\n",
        "                A = np.array([p[index] for p in population])\n",
        "                self.weights[index] = (\n",
        "                    w\n",
        "                    + self.learning_rate\n",
        "                    / (self.population_size * self.sigma)\n",
        "                    * np.dot(A.T, rewards).T\n",
        "                )\n",
        "            if (i + 1) % print_every == 0:\n",
        "                print(\n",
        "                    'iter %d. reward: %f'\n",
        "                    % (i + 1, self.reward_function(self.weights))\n",
        "                )\n",
        "        print('time taken to train:', time.time() - lasttime, 'seconds')\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, input_size, layer_size, output_size):\n",
        "        self.weights = [\n",
        "            np.random.randn(input_size, layer_size),\n",
        "            np.random.randn(layer_size, output_size),\n",
        "            np.random.randn(layer_size, 1),\n",
        "            np.random.randn(1, layer_size),\n",
        "        ]\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        feed = np.dot(inputs, self.weights[0]) + self.weights[-1]\n",
        "        decision = np.dot(feed, self.weights[1])\n",
        "        buy = np.dot(feed, self.weights[2])\n",
        "        return decision, buy\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.weights = weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBV-Yr3s6_nb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(\n",
        "        self,\n",
        "        population_size,\n",
        "        sigma,\n",
        "        learning_rate,\n",
        "        model,\n",
        "        money,\n",
        "        max_buy,\n",
        "        max_sell,\n",
        "        skip,\n",
        "        window_size,\n",
        "    ):\n",
        "        self.window_size = window_size\n",
        "        self.skip = skip\n",
        "        self.POPULATION_SIZE = population_size\n",
        "        self.SIGMA = sigma\n",
        "        self.LEARNING_RATE = learning_rate\n",
        "        self.model = model\n",
        "        self.initial_money = money\n",
        "        self.max_buy = max_buy\n",
        "        self.max_sell = max_sell\n",
        "        self.es = Deep_Evolution_Strategy(\n",
        "            self.model.get_weights(),\n",
        "            self.get_reward,\n",
        "            self.POPULATION_SIZE,\n",
        "            self.SIGMA,\n",
        "            self.LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "    def act(self, sequence):\n",
        "        decision, buy = self.model.predict(np.array(sequence))\n",
        "        return np.argmax(decision[0]), int(buy[0])\n",
        "\n",
        "    def get_reward(self, weights):\n",
        "        initial_money = self.initial_money\n",
        "        starting_money = initial_money\n",
        "        self.model.weights = weights\n",
        "        state = get_state(close, 0, self.window_size + 1)\n",
        "        inventory = []\n",
        "        quantity = 0\n",
        "        for t in range(0, l, self.skip):\n",
        "            action, buy = self.act(state)\n",
        "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
        "            if action == 1 and initial_money >= close[t]:\n",
        "                if buy < 0:\n",
        "                    buy = 1\n",
        "                if buy > self.max_buy:\n",
        "                    buy_units = self.max_buy\n",
        "                else:\n",
        "                    buy_units = buy\n",
        "                total_buy = buy_units * close[t]\n",
        "                initial_money -= total_buy\n",
        "                inventory.append(total_buy)\n",
        "                quantity += buy_units\n",
        "            elif action == 2 and len(inventory) > 0:\n",
        "                if quantity > self.max_sell:\n",
        "                    sell_units = self.max_sell\n",
        "                else:\n",
        "                    sell_units = quantity\n",
        "                quantity -= sell_units\n",
        "                total_sell = sell_units * close[t]\n",
        "                initial_money += total_sell\n",
        "\n",
        "            state = next_state\n",
        "        return ((initial_money - starting_money) / starting_money) * 100\n",
        "\n",
        "    def fit(self, iterations, checkpoint):\n",
        "        self.es.train(iterations, print_every = checkpoint)\n",
        "\n",
        "    def buy(self):\n",
        "        initial_money = self.initial_money\n",
        "        state = get_state(close, 0, self.window_size + 1)\n",
        "        starting_money = initial_money\n",
        "        states_sell = []\n",
        "        states_buy = []\n",
        "        inventory = []\n",
        "        quantity = 0\n",
        "        for t in range(0, l, self.skip):\n",
        "            action, buy = self.act(state)\n",
        "            next_state = get_state(close, t + 1, self.window_size + 1)\n",
        "            if action == 1 and initial_money >= close[t]:\n",
        "                if buy < 0:\n",
        "                    buy = 1\n",
        "                if buy > self.max_buy:\n",
        "                    buy_units = self.max_buy\n",
        "                else:\n",
        "                    buy_units = buy\n",
        "                total_buy = buy_units * close[t]\n",
        "                initial_money -= total_buy\n",
        "                inventory.append(total_buy)\n",
        "                quantity += buy_units\n",
        "                states_buy.append(t)\n",
        "                print(\n",
        "                    'day %d: buy %d units at price %f, total balance %f'\n",
        "                    % (t, buy_units, total_buy, initial_money)\n",
        "                )\n",
        "            elif action == 2 and len(inventory) > 0:\n",
        "                bought_price = inventory.pop(0)\n",
        "                if quantity > self.max_sell:\n",
        "                    sell_units = self.max_sell\n",
        "                else:\n",
        "                    sell_units = quantity\n",
        "                if sell_units < 1:\n",
        "                    continue\n",
        "                quantity -= sell_units\n",
        "                total_sell = sell_units * close[t]\n",
        "                initial_money += total_sell\n",
        "                states_sell.append(t)\n",
        "                try:\n",
        "                    invest = ((total_sell - bought_price) / bought_price) * 100\n",
        "                except:\n",
        "                    invest = 0\n",
        "                print(\n",
        "                    'day %d, sell %d units at price %f, investment %f %%, total balance %f,'\n",
        "                    % (t, sell_units, total_sell, invest, initial_money)\n",
        "                )\n",
        "            state = next_state\n",
        "\n",
        "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
        "        print(\n",
        "            '\\ntotal gained %f, total investment %f %%'\n",
        "            % (initial_money - starting_money, invest)\n",
        "        )\n",
        "        plt.figure(figsize = (20, 10))\n",
        "        plt.title(ticker + \": Predicted Buy/Sell for \" +str(len(close))+ \" Days with ROI: \" + str(int(invest))+\"%\",fontsize=24, y=1)\n",
        "\n",
        "        plt.plot(close, label = 'true close', c = 'g')\n",
        "        plt.plot(\n",
        "            close, 'X', label = 'predict buy', markevery = states_buy, c = 'b'\n",
        "        )\n",
        "        plt.plot(\n",
        "            close, 'o', label = 'predict sell', markevery = states_sell, c = 'r'\n",
        "        )\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_d7Gdz_T_wXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimzier"
      ]
    },
    {
      "metadata": {
        "id": "-ZvP59gL6_nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def best_agent(\n",
        "    window_size, skip, population_size, sigma, learning_rate, size_network\n",
        "):\n",
        "    model = Model(window_size, size_network, 3)\n",
        "    agent = Agent(\n",
        "        population_size,\n",
        "        sigma,\n",
        "        learning_rate,\n",
        "        model,\n",
        "        10000,\n",
        "        5,\n",
        "        5,\n",
        "        skip,\n",
        "        window_size,\n",
        "    )\n",
        "    try:\n",
        "        agent.fit(100, 1000)\n",
        "        return agent.es.reward_function(agent.es.weights)\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "je6LFcLd6_oF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_best_agent(\n",
        "    window_size, skip, population_size, sigma, learning_rate, size_network\n",
        "):\n",
        "    global accbest\n",
        "    param = {\n",
        "        'window_size': int(np.around(window_size)),\n",
        "        'skip': int(np.around(skip)),\n",
        "        'population_size': int(np.around(population_size)),\n",
        "        'sigma': max(min(sigma, 1), 0.0001),\n",
        "        'learning_rate': max(min(learning_rate, 0.5), 0.000001),\n",
        "        'size_network': int(np.around(size_network)),\n",
        "    }\n",
        "    print('\\nSearch parameters %s' % (param))\n",
        "    investment = best_agent(**param)\n",
        "    print('stop after 100 iteration with investment %f' % (investment))\n",
        "    if investment > accbest:\n",
        "        costbest = investment\n",
        "    return investment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rl7M4CTn_pcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run optimizer"
      ]
    },
    {
      "metadata": {
        "id": "Msa9_cMd6_oQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accbest = 0.0\n",
        "NN_BAYESIAN = BayesianOptimization(\n",
        "    find_best_agent,\n",
        "    {\n",
        "        'window_size': (2, 50),\n",
        "        'skip': (1, 15),\n",
        "        'population_size': (1, 50),\n",
        "        'sigma': (0.01, 0.99),\n",
        "        'learning_rate': (0.000001, 0.49),\n",
        "        'size_network': (10, 1000),\n",
        "    },\n",
        ")\n",
        "NN_BAYESIAN.maximize(init_points = 30, n_iter = 50, acq = 'ei', xi = 0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7q7_Vrqu6_od",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Best AGENT accuracy value: %f' % NN_BAYESIAN.res['max']['max_val'])\n",
        "print('Best AGENT parameters: ', NN_BAYESIAN.res['max']['max_params'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mz7zaOir6_or",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### My selected parameters"
      ]
    },
    {
      "metadata": {
        "id": "ukgYprrX6_ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_agent(\n",
        "    window_size = 30, \n",
        "    skip = 1, \n",
        "    population_size = 15, \n",
        "    sigma = 0.1, \n",
        "    learning_rate = 0.03, \n",
        "    size_network = 500\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loQpyZ766_o8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### bayesian parameters"
      ]
    },
    {
      "metadata": {
        "id": "xNgQ3lPi6_pA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_agent(\n",
        "    window_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['window_size'])), \n",
        "    skip = int(np.around(NN_BAYESIAN.res['max']['max_params']['skip'])), \n",
        "    population_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['population_size'])), \n",
        "    sigma = NN_BAYESIAN.res['max']['max_params']['sigma'], \n",
        "    learning_rate = NN_BAYESIAN.res['max']['max_params']['learning_rate'], \n",
        "    size_network = int(np.around(NN_BAYESIAN.res['max']['max_params']['size_network']))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M4xtEYT_6_pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### My selected parameters"
      ]
    },
    {
      "metadata": {
        "id": "vyLTMbeK6_pg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(input_size = 30, \n",
        "              layer_size = 500, \n",
        "              output_size = 3)\n",
        "agent = Agent(population_size = 15, \n",
        "              sigma = 0.1, \n",
        "              learning_rate = 0.03, \n",
        "              model = model, \n",
        "              money = 10000, \n",
        "              max_buy = 5, \n",
        "              max_sell = 5, \n",
        "              skip = 1, \n",
        "              window_size = 30)\n",
        "agent.fit(500, 100)\n",
        "agent.buy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXk6xQzn6_p7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### bayesian parameters"
      ]
    },
    {
      "metadata": {
        "id": "qlwR0CPO6_p_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(input_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['window_size'])), \n",
        "              layer_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['size_network'])), \n",
        "              output_size = 3)\n",
        "agent = Agent(population_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['population_size'])), \n",
        "              sigma = NN_BAYESIAN.res['max']['max_params']['sigma'], \n",
        "              learning_rate = NN_BAYESIAN.res['max']['max_params']['learning_rate'], \n",
        "              model = model, \n",
        "              money = 10000, \n",
        "              max_buy = 5, \n",
        "              max_sell = 5, \n",
        "              skip = int(np.around(NN_BAYESIAN.res['max']['max_params']['skip'])), \n",
        "              window_size = int(np.around(NN_BAYESIAN.res['max']['max_params']['window_size'])))\n",
        "agent.fit(500, 100)\n",
        "agent.buy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8t92K2B6_qL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}